{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD\n",
    "\n",
    "LOAD corpus.pkl and query.csv(with tokenized) for certain language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# bm25_query\n",
    "def bm25_score(queries,corpus_file):\n",
    "    # load the preprocessed data\n",
    "    idf_times_F_adjusted, vectorizer, doc_ids = joblib.load(corpus_file)\n",
    "    \n",
    "    # preprocess the query\n",
    "    query_term_matrix = vectorizer.transform(queries['query_token'])\n",
    "    \n",
    "    # calculate the BM25 scores\n",
    "    BM25_scores = query_term_matrix @ idf_times_F_adjusted.T\n",
    "    \n",
    "    # get the top 10 documents for each query\n",
    "    pos_docs = {}\n",
    "    for query_idx, query_id in enumerate(queries['query_id']):\n",
    "        scores = BM25_scores[query_idx]\n",
    "        top_doc_indices = np.argsort(scores)[-10:][::-1]\n",
    "        pos_docs[query_id] = [doc_ids[idx] for idx in top_doc_indices]\n",
    "    \n",
    "    return pos_docs\n",
    "\n",
    "# run\n",
    "lang = 'fr'  \n",
    "corpus_path = f\"Data/test/bm25_{lang}_corpus.pkl\"  # corpus file\n",
    "query_file =pd.read_csv(f\"Data/test/bm25_{lang}_query.csv\")  # query file\n",
    "pos_docs = bm25_score(query_file, corpus_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the performance\n",
    "query = pd.read_csv('Data/dev.csv')\n",
    "# make a dictionary for query\n",
    "query_dict = {}\n",
    "for i in range(len(query)):\n",
    "    query_dict[query['query_id'][i]] = query['positive_docs'][i]\n",
    "\n",
    "\n",
    "acc = 0\n",
    "# if the positive documents are in the top 10, acc += 1\n",
    "for key in pos_docs.keys():\n",
    "    if query_dict[key] in pos_docs[key]:\n",
    "        acc += 1\n",
    "\n",
    "print(\"Accuracy: \", acc/len(pos_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = pd.read_csv(f\"Data/bm25query_{lang}_test.csv\")\n",
    "\n",
    "pos_docs = bm25_score(test_file, corpus_path)\n",
    "\n",
    "# save the results as csv\n",
    "\n",
    "with open(f\"Data/bm25_results_{lang}.csv\", \"w\") as f:\n",
    "    f.write(\"id,doc_id\\n\")\n",
    "    for key in pos_docs.keys():\n",
    "        f.write(f\"{key},{' '.join(pos_docs[key])}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
